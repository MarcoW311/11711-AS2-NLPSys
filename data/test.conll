We O
approach O
the O
problem O
with O
a O
mix O
of O
statistics O
- O
based O
quantization O
for O
the O
weights O
and O
elastic O
quantization O
of O
the O
activations O
and O
demonstrate O
the O
first O
ternary O
and O
binary O
transformer O
models O
on O
the O
downstream O
tasks O
of O
summarization B-TaskName
and O
machine B-TaskName
translation I-TaskName
. O

Our O
ternary O
BART B-MethodName
base O
achieves O
an O
R1 B-MetricName
score O
of O
41 B-MetricValue
on O
the O
CNN B-DatasetName
/ I-DatasetName
DailyMail I-DatasetName
benchmark O
, O
which O
is O
merely O
3.9 O
points O
behind O
the O
full O
model O
while O
being O
16x O
more O
efficient O
. O

Our O
binary O
model O
, O
while O
less O
accurate O
, O
achieves O
a O
highly O
nontrivial O
score O
of O
35.6 O
. O
For O
machine O
translation O
, O
we O
achieved O
BLEU B-MetricName
scores O
of O
21.7 B-MetricValue
and O
17.6 B-MetricValue
on O
the O
WMT16 B-DatasetName
En I-DatasetName
- I-DatasetName
Ro I-DatasetName
benchmark O
, O
compared O
with O
a O
full O
precision O
mBART B-MethodName
model O
score O
of O
26.8 O
. O
We O
also O
compare O
our O
approach O
in O
the O
8 O
- O
bit O
activation O
setting O
, O
where O
our O
ternary O
and O
even O
binary O
weight O
models O
can O
match O
or O
outperform O
the O
best O
existing O
8 O
- O
bit O
weight O
models O
in O
the O
literature O
. O

Most O
of O
this O
work O
focuses O
on O
encoder O
- O
only O
models O
( O
mainly O
BERT B-MethodName
) O
for O
sentence O
and O
token O
classification O
tasks O
. O

Our O
ternary O
( O
weight O
and O
activation O
) O
model O
lags O
a O
full O
- O
precision O
BART B-MethodName
( O
Lewis O
et O
al O
. O
, O
2020 O
) O
model O
by O
only O
4 B-MetricValue
points O
in O
ROUGE B-MetricName
on O
the O
XSUM B-DatasetName
summarization O
dataset O
. O

While O
not O
as O
competitive O
, O
it O
is O
able O
to O
achieve O
a O
highly O
non O
- O
trivial O
ROUGE-1 B-MetricName
score O
of O
31.7 B-MetricValue
. O
Our O
results O
also O
extend O
to O
machine O
translation O
models O
. O

On O
the O
WMT16 B-DatasetName
En I-DatasetName
- I-DatasetName
Ro I-DatasetName
benchmark O
, O
we O
quantize O
an O
mBART B-MethodName
model O
to O
extend O
the O
ternaryweight O
8 O
- O
bit O
activation O
SoTA O
by O
1.2 O
points O
while O
demonstrating O
fully O
ternary O
and O
fully O
binary O
translation O
models O
for O
the O
first O
time O
. O

We O
abbreviate O
our O
method O
as O
TBT B-MethodName
, O
short O
for O
“ O
Ternary O
/ O
Binary O
Transformer O
” O
. O

3 O
Experiments O
In O
this O
section O
, O
we O
evaluate O
the O
effectiveness O
of O
our O
low O
- O
bit O
quantization O
scheme O
for O
natural O
language O
generative O
model O
on O
text B-TaskName
summarization I-TaskName
benchmarks O
: O
CNN B-DatasetName
/ I-DatasetName
DailyMail I-DatasetName
( O
Nallapati O
et O
al O
. O
, O
2016 O
) O
and O
XSUM B-DatasetName
( O
Narayan O
et O
al O
. O
, O
2018 O
) O
. O

We O
train O
the O
quantized O
models O
for O
20 B-HyperparameterValue
epochs B-HyperparameterName
on O
8 O
GPUs O
with O
a O
batch B-HyperparameterName
size I-HyperparameterName
of O
128 B-HyperparameterValue
and O
a O
learning B-HyperparameterName
rate I-HyperparameterName
of O
2.5e-4 B-HyperparameterValue
for O
8 O
- O
bit O
activation O
models O
and O
5e-4 B-HyperparameterValue
for O
binary O
and O
ternary O
activation O
models O
. O

The O
results O
of O
QuantBart B-MethodName
, O
DQ B-MethodName
- I-MethodName
BART I-MethodName
and O
BlockPruning B-MethodName
are O
quoted O
from O
their O
paper O
. O

Additionally O
, O
we O
implement O
the O
algorithm O
developed O
in O
BinaryBert B-MethodName
, O
BiBert B-MethodName
and O
TernaryBert B-MethodName
to O
the O
BART B-MethodName
model O
and O
report O
the O
results O
, O
denoted O
with∗ O
. O

We O
use O
BART B-MethodName
- O
base O
model O
( O
Lewis O
et O
al O
. O
, O
2019 O
) O
, O
which O
is O
an O
English O
- O
only O
encoder O
- O
decoder O
transformer O
with O
140 O
million O
parameters O
. O

We O
compare O
using O
the O
standard O
ROUGE- B-MetricName
{ I-MetricName
1,2 I-MetricName
, I-MetricName
l I-MetricName
} I-MetricName
metrics O
for O
this O
task O
. O

For O
the O
ternary O
weights O
and O
8 O
- O
bit O
activations O
setting O
, O
we O
compare O
with O
two O
state O
- O
of O
- O
the O
- O
art O
methods O
QuantBart B-MethodName
( O
Tao O
et O
al O
. O
, O
2022 O
) O
and O
DQ B-MethodName
- I-MethodName
BART I-MethodName
( O
Li O
et O
al O
. O
, O
2022 O
) O
. O

Therefore O
we O
provide O
a O
naive O
quantization O
baseline O
, O
using O
popular O
implementations O
from O
previous O
work O
( O
Li O
et O
al O
. O
, O
2016 O
; O
Courbariaux O
et O
al O
. O
, O
2016 O
) O
, O
and O
adapt O
the O
binary O
and O
ternary O
methods O
proposed O
for O
the O
BERT B-MethodName
models O
( O
Bai O
et O
al O
. O
, O
2021b O
; O
Qin O
et O
al O
. O
, O
2021 O
; O
Zhang O
et O
al O
. O
, O
2020 O
) O
to O
BART B-MethodName
. O

In O
the O
ternary O
weights O
and O
8 O
- O
bit O
activations O
setting O
, O
TBTimproves B-MethodName
previous O
SoTA O
by O
up O
to O
2.3 B-MetricValue
points O
in O
ROUGE B-MetricName
score O
on O
XSUM B-DatasetName
, O
and O
up O
to O
0.5 B-MetricValue
points O
on O
CNN B-DatasetName
/ I-DatasetName
DailyMail I-DatasetName
. O

Both O
improvements O
are O
significant O
. O
Further O
quantizing O
weights O
to O
binary O
, O
while O
keeping O
activations O
at O
8 O
- O
bit O
, O
we O
are O
still O
able O
to O
achieve O
a O
ROUGE B-MetricName
- I-MetricName
L I-MetricName
score O
of O
33.3 B-MetricValue
on O
XSUM B-DatasetName
, O
which O
is O
0.8 B-MetricValue
points O
higher O
than O
the O
previous O
ternary O
SoTA O
( O
DQBART B-MethodName
) O
, O
and O
comparable O
on O
CNN B-MetricName
/ I-MetricName
DailyMail I-MetricName
. O

Additionally O
, O
TBTbinary O
weight O
BART B-MethodName
model O
achieves O
1.2 B-MetricValue
points O
higher O
ROUGE B-MetricName
score O
on O
CNN O
compared O
with O
the O
SoTA O
pruning O
method O
with O
the O
same O
compressed O
model O
size O
. O

Our O
method O
, O
on O
the O
other O
hand O
, O
achieves O
ROUGE B-MetricName
- I-MetricName
L I-MetricName
scores O
of O
29.1 B-MetricValue
and O
38.3 B-MetricValue
on O
XSUM B-DatasetName
and O
CNN B-MetricValue
/ I-MetricValue
DailyMail I-MetricValue
in O
the O
fully O
ternary O
setting O
, O
which O
are O
6.6 B-MetricValue
and O
3.8 B-MetricValue
points O
behind O
the O
full O
- O
precision O
baseline O
respectively O
. O

Our O
fully O
binary O
( O
weights O
and O
activations O
) O
model O
has O
a O
wider O
gap O
at O
10.4 B-MetricValue
and O
8.9 B-MetricValue
points O
, O
however O
still O
manages O
to O
produce O
highly O
non O
- O
trivial O
output O
at O
ROUGE B-MetricName
- I-MetricName
L I-MetricName
scores O
of O
25.3 B-MetricValue
and O
33.2 B-MetricValue
points O
for O
XSUM B-DatasetName
and O
CNN B-DatasetName
/ I-DatasetName
DailyMail I-DatasetName
. O

3.3 O
Machine B-TaskName
translation I-TaskName
We O
also O
evaluate O
our O
model O
on O
machine B-TaskName
translation I-TaskName
. O

In O
the O
ternary O
weight O
setting O
with O
8 O
- O
bit O
activations O
, O
we O
improve O
the O
previous O
SoTA O
by O
1.2 O
points O
, O
achieving O
24.63 B-MetricValue
BLEU B-MetricName
. O

It O
scores O
24.3 B-MetricValue
BLEU B-MetricName
– O
only O
1.5 B-MetricValue
points O
behind O
a O
full O
mBART O
model O
while O
being O
16×smaller O
. O

In O
the O
fully O
ternary O
and O
binary O
settings O
, O
where O
previous O
methods O
failed O
to O
converge O
, O
TBTmodels O
are O
able O
to O
reach O
practical O
levels O
of O
performance O
, O
with O
ternary O
TBTmBART O
achieving O
21.7 B-MetricValue
BLEU B-MetricName
, O
andTBTbinary O
mBART O
at O
17.59 B-MetricValue
. O

None O
of O
the O
ablated O
models O
can O
achieve O
an O
R2 B-MetricName
score O
above O
1.5 B-MetricValue
. O
It O
’s O
only O
the O
combination O
of O
the O
two O
, O
which O
together O
stabilize O
the O
training O
and O
result O
in O
good O
convergence O
for O
fully O
ternary O
and O
binary O
models O
. O

In O
Table O
4 O
we O
compare O
the O
generated O
sequence O
length O
between O
the O
proposed O
method O
and O
the O
baseline O
method O
( O
i.e. O
, O
TWN B-MethodName
( O
Li O
et O
al O
. O
, O
2016 O
) O
for O
ternary O
, O
BWN B-MethodName
( O
Courbariaux O
et O
al O
. O
, O
2016 O
) O
for O
binary O
) O
. O

Our O
method O
successfully O
produces O
summarizations O
with O
comparable O
length O
as O
the O
full O
- O
precision O
model O
on O
XSUM B-DatasetName
benchmark O
, O
even O
when O
both O
weights O
and O
activations O
are O
binarized O
. O

Compared O
to O
XSUM B-DatasetName
dataset O
, O
for O
which O
the O
document O
are O
summarized O
to O
only O
one O
sentence O
, O
CNN B-DatasetName
/ I-DatasetName
DailyMail I-DatasetName
is O
more O
challenging O
because O
it O
allows O
longer O
summary O
. O

reasonable O
summarization O
with O
2 O
- O
bit O
weight O
8 O
- O
bit O
activations O
and O
fails O
at O
lower O
bit O
- O
width O
, O
showing O
the O
difficult O
natural O
of O
the O
language B-TaskName
generation I-TaskName
tasks O
. O

Due O
to O
the O
popularity O
of O
BERT B-MethodName
, O
numerous O
works O
have O
studied O
quantization O
for O
transformer O
models O
, O
starting O
with O
8 O
- O
bit O
quantization O
( O
Zafrir O
et O
al O
. O
, O
2019 O
; O
Fan O
et O
al O
. O
, O
2020 O
) O
, O
and O
progressing O
to O
4 O
- O
bit O
( O
Shen O
et O
al O
. O
, O
2020 O
; O
Zadeh O
et O
al O
. O
, O
2020 O
) O
, O
ternary O
( O
Zhang O
et O
al O
. O
, O
2020 O
) O
and O
binary O
Bai O
et O
al O
. O

5 O
Conclusion O
We O
have O
demonstrated O
high O
accuracy O
ternary O
and O
binary O
natural B-TaskName
language I-TaskName
generation I-TaskName
models O
based O
on O
a O
pre O
- O
trained O
transformer O
encoder O
- O
decoder O
backbone O
. O

We O
are O
especially O
excited O
about O
the O
implications O
of O
our O
results O
for O
larger O
text B-TaskName
generation I-TaskName
models O
such O
as O
GPT-3 B-MethodName
( O
Brown O
et O
al O
. O
, O
2020 O
) O
. O

6 O
Limitations O
We O
conduct O
experiments O
on O
public O
datasets O
of O
finite O
sentence B-HyperparameterName
length I-HyperparameterName
, O
while O
generalizability O
to O
extremely O
long O
sequences O
or O
even O
streaming O
data O
has O
not O
been O
verified O
. O

Furthermore O
, O
the O
generalizability O
of O
the O
proposed O
quantization O
method O
to O
other O
tasks O
, O
including O
computer B-TaskName
vision I-TaskName
or O
speech B-TaskName
recognition I-TaskName
, O
remains O
to O
be O
tested O
. O

There O
is O
some O
potential O
risk O
if O
the O
translation O
technique O
is O
maliciouslyused O
by O
a O
third O
party O
and O
thus O
we O
are O
committed O
to O
maintaining O
the O
compression O
techniques O
we O
have O
developed O
and O
the O
general O
summarization B-TaskName
/ O
machine B-TaskName
translation I-TaskName
techniques O
used O
correctly O
without O
incurring O
any O
form O
of O
discrimination O
. O

